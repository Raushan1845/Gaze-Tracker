{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9221262-43d1-4a22-8972-99392fcae8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee388b-14e9-4ed9-8aaf-7b67340b4dac",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d5f64f-717b-40c6-8c23-94d552730437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eye_model(Model):\n",
    "  def __init__(self):\n",
    "    super(eye_model, self).__init__(name='')\n",
    "\n",
    "    self.conv1 = layers.Conv2D(32, kernel_size=7, strides=2, padding='valid')\n",
    "    self.conv2 = layers.Conv2D(64, kernel_size=5, strides=2, padding='valid')\n",
    "    self.conv3 = layers.Conv2D(128, kernel_size=3, strides=1, padding='valid')\n",
    "    self.bn = layers.BatchNormalization(axis = 1, momentum=0.9)\n",
    "    self.leakyrelu = layers.LeakyReLU(alpha=0.01) \n",
    "    self.avgpool = layers.AveragePooling2D(pool_size=2)\n",
    "    self.dropout = layers.Dropout(rate=0.02)\n",
    "    \n",
    "\n",
    "  def call(self, input_tensor):\n",
    "    x = self.conv1(input_tensor)\n",
    "    x = self.bn(x)\n",
    "    x = self.leakyrelu(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.leakyrelu(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.leakyrelu(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "class landmark_model(Model):\n",
    "  def __init__(self):\n",
    "    super(landmark_model, self).__init__(name='')\n",
    "\n",
    "    self.dense1 = layers.Dense(128)\n",
    "    self.dense2 = layers.Dense(16)\n",
    "    self.dense3 = layers.Dense(16)\n",
    "    self.bn = layers.BatchNormalization(momentum=0.9)\n",
    "    self.relu = layers.ReLU()\n",
    "\n",
    "  def call(self, input_tensor):\n",
    "    x = self.dense1(input_tensor)\n",
    "    x = self.bn(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dense2(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dense3(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.relu(x)   \n",
    "    \n",
    "    return x\n",
    "\n",
    "class gazetrack_model(Model):\n",
    "  def __init__(self):\n",
    "    super(gazetrack_model, self).__init__(name='')\n",
    "\n",
    "    self.eye_model = eye_model()\n",
    "    self.lmModel = landmark_model()\n",
    "    \n",
    "    self.dense1 = layers.Dense(8)\n",
    "    self.dense2 = layers.Dense(4)\n",
    "    self.dense3 = layers.Dense(2)\n",
    "    \n",
    "    self.bn = layers.BatchNormalization(momentum=0.9)\n",
    "    self.dropout = layers.Dropout(rate=0.12)\n",
    "    self.relu = layers.ReLU()\n",
    "\n",
    "    \n",
    "\n",
    "  def call(self, leftEye, rightEye, lms):\n",
    "    l_eye_feat = tf.reshape(self.eye_model(leftEye), (3, 128*128))\n",
    "    r_eye_feat = tf.reshape(self.eye_model(rightEye), (3, 128*128))\n",
    "    \n",
    "    lm_feat = self.lmModel(lms)\n",
    "    \n",
    "    combined_feat = tf.concat((l_eye_feat, r_eye_feat, lm_feat),1)\n",
    "    \n",
    "    x = self.dense1(combined_feat)\n",
    "    x = self.bn(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dense2(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dense3(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "model = gazetrack_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb16557-db80-417e-9c9b-2dd2d034d946",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352428b-3e8a-41cf-a608-8f6b28f0fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "opt = SGD(learning_rate=learning_rate)\n",
    "\n",
    "# COMPILE\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# FIT\n",
    "model.fit(\n",
    "    x=get_dataset(train_filenames, batch_size),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# SAVE\n",
    "model.save(args.model_output + '/1')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f5976-c741-4ff8-b5fa-66504ac1a3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede67075-34dd-43bc-9aa5-2e300e53529a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be134d74-ef8b-4b4e-af66-79e0e6df0dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a883c-3274-4aaa-8be1-61a9e425e445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3465ba9-33d0-4051-addc-3fa6e71f9cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfa8be-27d7-4f17-b75a-d93c5e054e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dde05e-a04c-48ef-a4de-54af9d8a4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA\n",
    "validation_array = np.array(list(validation_dataset.unbatch().take(-1).as_numpy_iterator()))\n",
    "test_x = np.stack(validation_array[:,0])\n",
    "test_y = np.stack(validation_array[:,1])\n",
    "\n",
    "# Use the model to predict the labels\n",
    "test_predictions = model.predict(test_x)\n",
    "test_y_pred = np.argmax(test_predictions, axis=1)\n",
    "test_y_true = np.argmax(test_y, axis=1)\n",
    "\n",
    "# Evaluating model accuracy and logging it as a scalar for TensorBoard hyperparameter visualization.\n",
    "accuracy = sklearn.metrics.accuracy_score(test_y_true, test_y_pred)\n",
    "tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "logging.info('Test accuracy:{}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
